# Домашнее задание к занятию "10.06. Инцидент-менеджмент"


> Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.

> Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

## Постмортем

### Краткое описание инцидента             
Issue и комментарии к ним пропадают после перезагрузки страницы.

### Предшествующие события
Производилась замена неисправного 100G оптического оборудования между сетевым хабом и датацентром на восточном побережье США. В результате замены связь была восстанвовлена в течение 43 секунд.

### Причина инидента
В результате краткосрочной потери сетевого соединения произошла рассинхронизация между репликами распределённой базы данных  MySQL.

### Воздействие
Польззователи не могли отправлять Issues и комментарии к ним в течение 24 часов и 11 минут. Так же не работали вебхуки, сборка и публикация GitHub Pages.

### Обнаружение
Проблема была обнуражена дежурным инженером.

### Реакция
Системные администраторы устранили проблему за 24 часа и 11 минут.

### Восстановление       
Несколько команд инженеров проанализировали двоичные логи чтобы разделить данные, которые могут быть автоматически востановленны, от нереплицированных на серверах Западного побережья данных. Помио этого была определена категория записей в базе данных, которая содержала повторяли записи, произведённые пользователями при рассинхронизации баз данных. В результате была восстановлена целостность базы данных.

### Таймлайн
22:52 UTC - в результате кратковременного обрыва связи между датацентрами после восстановления связи на географически разделённых серверах сеобразовались записи, которых не было на другом сервере, в результате чего возникла проблема с назначением основного сервера.

22:54 UTC - система мониторигна начала подавать сигналы тревоги из за многичесленных ошибок.

23:02 UTC - инженеры мониоринга определили что топология нескольких баз данных в кластере находится в неправильном состоянии. Репликация происходит только с серверами Западного побережья.

23:07 UTC - инженероы мониторинга решают блокировать подсистему деплоя чтобы предотварить любые изменения в условиях рассинхронизации базы данных.

23:09 UTC - инженеры мониторинга устанавливают статус "жёлтый". Это автоматически приводит к экскалации инцидента и производит оповещение инцидент-координатора.

23:11 UTC - инцидент координатор устанавливет статус "красный"

23:13 UTC - приглашены DBA инженеры, они вручную конфигурирую сервера баз данных восточном побережье и перенастраивают топологию репликации.

23:19 UTC - были остановлены задачи, которые записывают метаданные. Было принято рещение частично ограничить некоторые сервисы, дабы исключить риск потери данных.

00:05 UTC - инженеры коипнды реагирования приняли рещение о восстановлении данных из бэкапа, синхронизации реплик и возврате к стабильной топологии сервиса.

00:41 UTC - начат процесс восстановления из бэкапа.

06:51 UTC - несколько кластеров на Восточном побережье завершили процесс восстановления из бэкапа и начали реплицирования новых данных на сервера Западного побережья.

07:46 UTC - был опубликован пост в блоге предоставляющий информацию о ситуации. Этот пост так же послужил для тества работоспособности подсистемы.

11:12 UTC - все первичные базы данных восстановились на восточном побережель. В результате сайт стал более отзывчивым, поскольку все записи направляли на сервера, размещённые в том же датацентре, что и сервера уровня приложений.

13:15 UTC - была достигнута пикова нагрузка на GitHub.com                                                

16:24 UTC - реплики были синхронизированы, но было принято решение оставить сервис красным до обработки накопленных данных.

16:45 UTC - заработали вебхуки. Около 200000 из них оказались просрочены и для них был временно обновлён TTL.

23:03 UTC - все отложенные вебхуки отработали, страницы сборок были обновлены, целостность и корректное функционерование были подтверждены. Статус сайта переведён в "зелёный".

### Последующие действия
1. Настройка конфгурации оркестратора, предотвращающей продвижение первичных баз данных через региональные границы.
2. Исползование расширенных статусов мониторинга, которые позволят дать более точную картину происходящего. Реализация индивидуального отображения статуса для каждого компонента платформы.
3. Реализация обслуживание трафика из множества датацентров в режиме active/active/active. Это защитит в случае полного выхода из строя одного из датацентров. 
4. Систематическая проверка сценариев сбоев.

<!--
## Задача повышенной сложности

Прослушайте [симуляцию аудиозаписи о инциденте](https://youtu.be/vw6I5DYWkNA?t=1), предоставленную 
разработчиками инструмента для автоматизации инцидент-менеджмента PagerDuty.

На основании этой аудиозаписи попробуйте составить сообщения для пользователей о данном инциденте.

Должно быть 3 сообщения о:
- начале инцидента
- продолжающихся работах
- окончании инцидента и возвращении к штатной работе

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---

-->
